{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('What is light ?', 'Qu’est-ce que la lumière?'),\n",
       "  ('Who are we?', 'Où sommes-nous?'),\n",
       "  ('Where did we come from?', \"D'où venons-nous?\"),\n",
       "  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n",
       "  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n",
       "   'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')],\n",
       " 52331)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['what', 'is', 'light', '?'],\n",
       " ['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 28.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([len(o) for o in en_tok], 90), np.percentile([len(o) for o in fr_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?', '_eos_'], 17573, 24793)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reversals(en, fr, rev_eng = False, rev_fre = False):\n",
    "    if (rev_eng and rev_fre):\n",
    "        en_rev = [a[::-1][1:]+a[::-1][0:1] for a in en]\n",
    "        fr_rev = [a[::-1][1:]+a[::-1][0:1] for a in fr]\n",
    "        return en_rev,fr_rev\n",
    "    elif (rev_eng):\n",
    "        en_rev = [a[::-1][1:]+a[::-1][0:1] for a in en]\n",
    "        return en_rev\n",
    "    elif (rev_fre):\n",
    "        fr_rev = [a[::-1][1:]+a[::-1][0:1] for a in fr]\n",
    "        return fr_rev\n",
    "    else:\n",
    "        print (\"Error in Reversals Code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 33)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_99 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_97 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_99,frlen_97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 26)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 90))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 90))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 122)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_100 = int(np.percentile([len(o) for o in en_ids], 100))\n",
    "frlen_100 = int(np.percentile([len(o) for o in fr_ids], 100))\n",
    "enlen_100,frlen_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_99] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_97] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_trn_rev, fr_trn_rev = reversals(en = en_trn, fr = fr_trn, rev_eng = True, rev_fre = True)\n",
    "en_val_rev, fr_val_rev = reversals(en = en_val, fr = fr_val, rev_eng = True, rev_fre = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Dataset - Both French and English sentences are straight\n",
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset 1 - French(Source) is reversed and English(Target) is straight\n",
    "trn_ds_1 = Seq2SeqDataset(fr_trn_rev,en_trn)\n",
    "val_ds_1 = Seq2SeqDataset(fr_val_rev,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset 2 - French(Source) is straight and English(Target) is reversed\n",
    "trn_ds_2 = Seq2SeqDataset(fr_trn,en_trn_rev)\n",
    "val_ds_2 = Seq2SeqDataset(fr_val,en_val_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Dataset 3 - Both French and English are reversed\n",
    "trn_ds_3 = Seq2SeqDataset(fr_trn_rev,en_trn_rev)\n",
    "val_ds_3 = Seq2SeqDataset(fr_val_rev,en_val_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=125\n",
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 29), (21, 7), (21, 8), (33, 13), (33, 21)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_99)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43de9f563c1e42aa9f8368c7a4c9dd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 238/362 [00:43<00:22,  5.50it/s, loss=31.2]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eced435c15564930b80b752d2d4ca71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.770847   8.513971  \n",
      "    1      3.378469   8.001781                              \n",
      "    2      3.028419   6.072838                              \n",
      "    3      2.897162   4.678954                              \n",
      "    4      2.844882   4.52825                               \n",
      "    5      2.863175   4.037238                              \n",
      "    6      2.700316   3.748082                              \n",
      "    7      2.739801   3.70536                               \n",
      "    8      2.850697   3.55738                               \n",
      "    9      2.97383    3.53295                               \n",
      "    10     2.716448   3.464918                              \n",
      "    11     2.706294   3.41725                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.41725])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['croyez', '-', 'vous', 'que', 'le', 'secteur', 'canadien', 'du', 'porc', 'pourrait', 'mieux', 'fabler', 'sur', 'les', 'possibilités', 'du', 'marché', 'pour', 'ma~', 'son', 'potentiel', 'commercial', 'au', 'cours', 'des', 'cinq', 'prochaines', 'années', '?', '_eos_']\n",
      "['which', 'countries', 'do', 'you', 'feel', 'are', 'likely', 'to', 'be', 'the', 'most', 'fo', '~', 'midable', 'competition', 'for', 'the', 'canadian', 'hog', '-', 'po~', 'sector', 'over', 'the', 'next', 'five', 'years', '?', '_eos_']\n",
      "['what', 'is', 'the', 'the', 'of', 'the', 'the', 'the', 'the', 'the', 'the', 'in', 'in', 'in', 'in', 'in', 'in', 'in', 'the', '?', '?', '?', '?', '_eos_']\n",
      "\n",
      "['quels', 'principaux', 'obstacles', 'limitent', \"l'\", 'accès', 'à', 'ces', 'marchés', 'et', 'quelles', 'mesures', \"l'\", 'industrie', 'et', 'le', 'gouvernement', 'pourraient', '-', 'ils', 'prendre', 'pour', 'rendre', 'le', 'porc', 'du', 'manitoba', 'plus', 'concurrentiel', 'sur', 'ces', 'marchés', 'en']\n",
      "['what', 'are', 'the', 'major', 'impediments', 'to', 'accessing', 'these', 'markets', ',', 'and', 'what', 'might', 'industry', 'and', 'government', 'do', 'to', 'make', 'manitoba', 'pork', 'more', 'competitive', 'in', 'these', 'expanding', 'markets', '?', '_eos_']\n",
      "['what', 'are', 'the', 'main', 'barriers', 'to', 'small', 'and', 'and', 'and', 'and', 'and', 'in', 'canada', 'canada', 'canada', 'canada', 'canada', 'in', '?', '?', '?', '_eos_', '_eos_', '_eos_']\n",
      "\n",
      "['quel', 'rôle', 'le', 'commissaire', 'général', 'a', '-t', '-il', 'joué', 'dans', 'la', 'promotion', 'du', 'pavillon', 'du', 'canada', 'grâce', 'à', 'sa', 'visite', 'à', 'saveur', 'technologique', 'de', 'la', 'région', 'de', 'tokyo', 'avant', \"l'\", 'expo', 'et', 'à']\n",
      "['what', 'role', 'did', 'the', 'commissioner', 'general', \"'s\", 'pre', '-', 'expo', 'techjin', 'tour', 'of', 'tokyo', 'region', 'and', 'its', 'media', 'coverage', 'play', 'in', 'the', 'promotion', 'of', 'the', 'canada', 'pavilion', '?', '_eos_']\n",
      "['what', 'role', 'the', 'the', 'role', 'the', 'the', 'in', 'in', 'the', 'in', 'the', 'in', 'the', 'the', 'in', 'the', 'in', 'the', 'in', 'the', 'in', 'the', 'in', 'the', '?', '?', '?', '?']\n",
      "\n",
      "['quel', 'rôle', 'le', 'commissaire', 'général', 'a', '-t', '-il', 'joué', 'dans', 'la', 'promotion', 'du', 'pavillon', 'du', 'canada', 'grâce', 'à', 'sa', 'visite', 'à', 'saveur', 'technologique', 'de', 'la', 'région', 'de', 'tokyo', 'avant', 'l’', 'expo', 'et', 'à']\n",
      "['what', 'role', 'did', 'the', 'commissioner', 'general', '’s', 'pre', '-', 'expo', 'techjin', 'tour', 'of', 'tokyo', 'region', 'and', 'its', 'media', 'coverage', 'play', 'in', 'the', 'promotion', 'of', 'the', 'canada', 'pavilion', '?', '_eos_']\n",
      "['what', 'role', 'the', 'the', 'role', 'the', 'the', 'in', 'the', 'the', 'in', 'the', 'the', 'in', 'the', 'in', 'the', 'in', 'the', 'in', 'the', 'in', 'the', 'in', 'the', '?', '?', '?', '?']\n",
      "\n",
      "[\"qu'\", 'est', '-ce', 'que', 'les', 'expériences', 'canadiennes', 'et', 'internationales', 'nous', 'révèlent', 'des', 'effets', 'de', 'ces', 'partenariats', 'sur', \"l'\", 'accès', 'aux', 'services', ',', 'leur', 'qualité', ',', 'leurs', 'coûts', 'et', 'leurs', 'résultats', '?', '_eos_']\n",
      "['what', 'is', 'known', ',', 'from', 'canadian', 'and', 'international', 'experience', ',', 'about', 'the', 'effects', 'of', 'these', 'partnerships', 'on', 'access', ',', 'quality', ',', 'costs', ',', 'and', 'outcomes', 'of', 'care', '?', '_eos_']\n",
      "['what', 'do', 'canadian', 'canadian', 'tell', 'us', 'us', 'us', 'us', 'us', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', '?', '?', '?', '?', '_eos_']\n",
      "\n",
      "['quelles', 'sont', 'les', 'répercussions', 'de', 'notre', 'nouvelle', 'compréhension', 'des', 'fonctions', 'du', 'cerveau', ',', 'et', 'leurs', 'relations', 'avec', 'le', 'comportement', ',', 'la', 'personnalité', ',', 'la', 'mémoire', ',', 'et', 'les', 'autres', 'états', 'mentaux', '?', '_eos_']\n",
      "['what', 'are', 'the', 'implications', 'of', 'our', 'rapidly', 'developing', 'understanding', 'of', 'brain', 'function', ',', 'and', 'its', 'relationship', 'to', 'behavior', ',', 'personality', ',', 'memory', ',', 'and', 'other', 'mental', 'states', '?', '_eos_']\n",
      "['what', 'are', 'the', 'implications', 'of', 'our', 'of', 'of', ',', ',', ',', ',', ',', ',', ',', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', '_eos_', '_eos_', '_eos_', '_eos_', '_eos_']\n",
      "\n",
      "['quel', 'devrait', 'être', 'le', 'mandat', 'stratégique', 'de', \"l'\", 'institut', 'pour', 'les', 'prochaines', 'années', ',', 'et', 'quelle', 'structure', 'serait', 'la', 'plus', 'appropriée', 'pour', \"l'\", 'accomplissement', 'de', 'ce', 'mandat', '?', '_eos_']\n",
      "['what', 'should', 'be', 'the', 'strategic', 'mandate', 'of', 'the', 'institute', 'in', 'the', 'coming', 'years', ',', 'and', 'what', 'is', 'the', 'most', 'appropriate', 'structure', 'for', 'the', 'achievement', 'of', 'this', 'mandate', '?', '_eos_']\n",
      "['what', 'should', 'the', 'the', 'mandate', 'of', 'the', 'the', 'the', 'the', 'the', 'and', 'and', 'and', 'the', '?', '?', '?', '?', '_eos_', '_eos_']\n",
      "\n",
      "['quand', 'convient', '-', 'il', 'de', 'tenir', 'compte', 'des', 'heures', 'de', 'travail', 'd’', 'une', 'personne', 'pour', 'déterminer', 'si', 'une', 'installation', 'atteint', 'ou', 'dépasse', 'le', 'seuil', 'des', '20', '000', 'heures', 'de', 'travail', 'établi', '?', '_eos_']\n",
      "['when', 'should', 'an', 'individual', '’s', 'time', 'spent', 'working', 'at', 'a', 'facility', 'be', 'counted', 'for', 'purposes', 'of', 'determining', 'whether', 'or', 'not', 'the', '20', '000', 'hour', 'threshold', 'is', 'exceeded', '?', '_eos_']\n",
      "['when', 'would', 'the', 'a', 'time', 'a', 'a', 'hours', 'hours', 'hours', 'hours', 'hours', 'hours', '?', '?', '?', '?', '?', '_eos_', '_eos_']\n",
      "\n",
      "['pourquoi', 'l’', 'organisme', 'a', '-t', '-il', 'sollicité', 'l’', 'apport', 'du', 'public', 'et', 'qu’', 'est', '-ce', 'qui', 'a', 'bien', 'pu', 'susciter', 'cette', 'forte', 'réponse', ',', 'alors', 'que', 'd’', 'autres', 'appels', 'de', 'la', 't_up', 'fec']\n",
      "['why', 'did', 'the', 'agency', 'ask', 'for', 'public', 'input', 'and', 'what', 'prompted', 'the', 'large', 'response', ',', 'while', 'other', 't_up', 'fec', 'requests', 'might', 'generate', 'only', 'a', 'dozen', 'or', 'so', 'comments', '?']\n",
      "['why', 'did', 'the', 'agency', 'to', 'to', 'to', 'to', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 't_up', 't_up', '?', '?', '?', '?', '_eos_', '_eos_']\n",
      "\n",
      "['quelles', 'mesures', 'faudrait', '-', 'il', 'envisager', 'en', 'vue', 'de', 'réduire', 'le', 'risque', 'si', 'les', 'tests', 'de', 'dépistage', 'du', 't_up', 'vwn', 'ne', 'sont', 'pas', 'disponibles', '?', '_eos_']\n",
      "['what', 'measures', 'should', 'be', 'considered', 'to', 'reduce', 'risk', 'if', 'tests', 'for', 't_up', 'wnv', 'are', 'not', 'available', 'and', 'finally', ',', 'what', 'areas', 'of', 't_up', 'wnv', 'research', 'need', 'focused', 'attention', '?']\n",
      "['what', 'measures', 'should', 'be', 'be', 'to', 'ensure', 'the', 'testing', 'not', 'not', 'not', 'not', 'screening', 'screening', '?', '?', '_eos_', '_eos_']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(0,10):\n",
    "    print([fr_itos[o] for o in x[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in y[:,i] if o != 1])\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds_1, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds_1, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 29), (33, 16), (29, 13), (33, 8), (33, 20)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_99)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2800784b16084ed6ac4399467dd82bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.6144     11.153067 \n",
      "    1      3.236925   7.617097                              \n",
      "    2      3.273386   6.124528                              \n",
      "    3      3.215901   4.477503                              \n",
      "    4      3.167266   4.664958                              \n",
      "    5      3.24353    4.262458                              \n",
      "    6      2.869129   3.94471                               \n",
      "    7      2.876016   3.82358                               \n",
      "    8      2.938379   3.619175                              \n",
      "    9      2.934167   3.776458                              \n",
      "    10     2.888705   3.565312                              \n",
      "    11     2.832448   3.498366                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.49837])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'années', 'prochaines', 'cinq', 'des', 'cours', 'au', 'commercial', 'potentiel', 'son', 'ma~', 'pour', 'marché', 'du', 'possibilités', 'les', 'sur', 'fabler', 'mieux', 'pourrait', 'porc', 'du', 'canadien', 'secteur', 'le', 'que', 'vous', '-', 'croyez', '_eos_']\n",
      "['which', 'countries', 'do', 'you', 'feel', 'are', 'likely', 'to', 'be', 'the', 'most', 'fo', '~', 'midable', 'competition', 'for', 'the', 'canadian', 'hog', '-', 'po~', 'sector', 'over', 'the', 'next', 'five', 'years', '?', '_eos_']\n",
      "['what', 'do', 'you', 'see', 'the', 'the', 'the', 'in', 'in', 'in', 'in', '?', '?', '?', '_eos_']\n",
      "\n",
      "['marchés', 'ces', 'sur', 'concurrentiel', 'plus', 'manitoba', 'du', 'porc', 'le', 'rendre', 'pour', 'prendre', 'ils', '-', 'pourraient', 'gouvernement', 'le', 'et', 'industrie', \"l'\", 'mesures', 'quelles', 'et', 'marchés', 'ces', 'à', 'accès', \"l'\", 'limitent', 'obstacles', 'principaux', 'quels', 'en']\n",
      "['what', 'are', 'the', 'major', 'impediments', 'to', 'accessing', 'these', 'markets', ',', 'and', 'what', 'might', 'industry', 'and', 'government', 'do', 'to', 'make', 'manitoba', 'pork', 'more', 'competitive', 'in', 'these', 'expanding', 'markets', '?', '_eos_']\n",
      "['what', 'are', 'the', 'barriers', 'barriers', 'barriers', 'to', 'to', 'canadian', 'canadian', 'government', 'to', 'canada', 'to', 'to', 'canada', 'and', 'and', 'canada', 'canada', '?', '?', '?', '_eos_']\n",
      "\n",
      "['et', 'expo', \"l'\", 'avant', 'tokyo', 'de', 'région', 'la', 'de', 'technologique', 'saveur', 'à', 'visite', 'sa', 'à', 'grâce', 'canada', 'du', 'pavillon', 'du', 'promotion', 'la', 'dans', 'joué', '-il', '-t', 'a', 'général', 'commissaire', 'le', 'rôle', 'quel', 'à']\n",
      "['what', 'role', 'did', 'the', 'commissioner', 'general', \"'s\", 'pre', '-', 'expo', 'techjin', 'tour', 'of', 'tokyo', 'region', 'and', 'its', 'media', 'coverage', 'play', 'in', 'the', 'promotion', 'of', 'the', 'canada', 'pavilion', '?', '_eos_']\n",
      "['what', 'role', 'did', 'the', 'role', 'of', 'the', 'in', 'in', 'in', 'the', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'the', '?', '?', '?', '?', '_eos_']\n",
      "\n",
      "['et', 'expo', 'l’', 'avant', 'tokyo', 'de', 'région', 'la', 'de', 'technologique', 'saveur', 'à', 'visite', 'sa', 'à', 'grâce', 'canada', 'du', 'pavillon', 'du', 'promotion', 'la', 'dans', 'joué', '-il', '-t', 'a', 'général', 'commissaire', 'le', 'rôle', 'quel', 'à']\n",
      "['what', 'role', 'did', 'the', 'commissioner', 'general', '’s', 'pre', '-', 'expo', 'techjin', 'tour', 'of', 'tokyo', 'region', 'and', 'its', 'media', 'coverage', 'play', 'in', 'the', 'promotion', 'of', 'the', 'canada', 'pavilion', '?', '_eos_']\n",
      "['what', 'role', 'did', 'the', 'role', 'of', 'the', 'in', 'in', 'in', 'the', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'the', 'the', '?', '?', '?', '?', '_eos_']\n",
      "\n",
      "['?', 'résultats', 'leurs', 'et', 'coûts', 'leurs', ',', 'qualité', 'leur', ',', 'services', 'aux', 'accès', \"l'\", 'sur', 'partenariats', 'ces', 'de', 'effets', 'des', 'révèlent', 'nous', 'internationales', 'et', 'canadiennes', 'expériences', 'les', 'que', '-ce', 'est', \"qu'\", '_eos_']\n",
      "['what', 'is', 'known', ',', 'from', 'canadian', 'and', 'international', 'experience', ',', 'about', 'the', 'effects', 'of', 'these', 'partnerships', 'on', 'access', ',', 'quality', ',', 'costs', ',', 'and', 'outcomes', 'of', 'care', '?', '_eos_']\n",
      "['what', 'is', 'the', 'impact', 'impact', 'impact', 'of', 'canada', ',', ',', ',', ',', ',', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', '?', '?', '?', '_eos_']\n",
      "\n",
      "['?', 'mentaux', 'états', 'autres', 'les', 'et', ',', 'mémoire', 'la', ',', 'personnalité', 'la', ',', 'comportement', 'le', 'avec', 'relations', 'leurs', 'et', ',', 'cerveau', 'du', 'fonctions', 'des', 'compréhension', 'nouvelle', 'notre', 'de', 'répercussions', 'les', 'sont', 'quelles', '_eos_']\n",
      "['what', 'are', 'the', 'implications', 'of', 'our', 'rapidly', 'developing', 'understanding', 'of', 'brain', 'function', ',', 'and', 'its', 'relationship', 'to', 'behavior', ',', 'personality', ',', 'memory', ',', 'and', 'other', 'mental', 'states', '?', '_eos_']\n",
      "['what', 'are', 'the', 'implications', 'of', 'our', 'brain', ',', ',', ',', ',', ',', ',', ',', 'and', 'and', 'and', 'and', 'and', 'and', 'and', '?', '?', '_eos_']\n",
      "\n",
      "['?', 'mandat', 'ce', 'de', 'accomplissement', \"l'\", 'pour', 'appropriée', 'plus', 'la', 'serait', 'structure', 'quelle', 'et', ',', 'années', 'prochaines', 'les', 'pour', 'institut', \"l'\", 'de', 'stratégique', 'mandat', 'le', 'être', 'devrait', 'quel', '_eos_']\n",
      "['what', 'should', 'be', 'the', 'strategic', 'mandate', 'of', 'the', 'institute', 'in', 'the', 'coming', 'years', ',', 'and', 'what', 'is', 'the', 'most', 'appropriate', 'structure', 'for', 'the', 'achievement', 'of', 'this', 'mandate', '?', '_eos_']\n",
      "['what', 'should', 'the', 'the', 'mandate', 'mandate', 'mandate', 'mandate', 'mandate', 'mandate', 'mandate', 'mandate', 'mandate', 'the', 'the', 'the', 'to', 'the', '?', '?', '?', '?', '_eos_']\n",
      "\n",
      "['?', 'établi', 'travail', 'de', 'heures', '000', '20', 'des', 'seuil', 'le', 'dépasse', 'ou', 'atteint', 'installation', 'une', 'si', 'déterminer', 'pour', 'personne', 'une', 'd’', 'travail', 'de', 'heures', 'des', 'compte', 'tenir', 'de', 'il', '-', 'convient', 'quand', '_eos_']\n",
      "['when', 'should', 'an', 'individual', '’s', 'time', 'spent', 'working', 'at', 'a', 'facility', 'be', 'counted', 'for', 'purposes', 'of', 'determining', 'whether', 'or', 'not', 'the', '20', '000', 'hour', 'threshold', 'is', 'exceeded', '?', '_eos_']\n",
      "['when', 'should', 'a', 'be', 'be', 'a', 'to', 'a', 'a', 'time', 'time', 'to', 'a', 'a', 'a', 'time', 'the', '?', '?', '?', '?', '?']\n",
      "\n",
      "['t_up', 'la', 'de', 'appels', 'autres', 'd’', 'que', 'alors', ',', 'réponse', 'forte', 'cette', 'susciter', 'pu', 'bien', 'a', 'qui', '-ce', 'est', 'qu’', 'et', 'public', 'du', 'apport', 'l’', 'sollicité', '-il', '-t', 'a', 'organisme', 'l’', 'pourquoi', 'fec']\n",
      "['why', 'did', 'the', 'agency', 'ask', 'for', 'public', 'input', 'and', 'what', 'prompted', 'the', 'large', 'response', ',', 'while', 'other', 't_up', 'fec', 'requests', 'might', 'generate', 'only', 'a', 'dozen', 'or', 'so', 'comments', '?']\n",
      "['why', 'did', 'the', 't_up', 'to', 'to', 'to', 'to', 'to', 'to', ',', ',', ',', ',', ',', ',', ',', 'the', 'the', 'the', '?', '?', '?', '?', '?']\n",
      "\n",
      "['?', 'disponibles', 'pas', 'sont', 'ne', 'vwn', 't_up', 'du', 'dépistage', 'de', 'tests', 'les', 'si', 'risque', 'le', 'réduire', 'de', 'vue', 'en', 'envisager', 'il', '-', 'faudrait', 'mesures', 'quelles', '_eos_']\n",
      "['what', 'measures', 'should', 'be', 'considered', 'to', 'reduce', 'risk', 'if', 'tests', 'for', 't_up', 'wnv', 'are', 'not', 'available', 'and', 'finally', ',', 'what', 'areas', 'of', 't_up', 'wnv', 'research', 'need', 'focused', 'attention', '?']\n",
      "['what', 'measures', 'should', 'be', 'done', 'to', 'to', 'risk', 'risk', 'for', 'for', 'for', '?', '?', '?', '?', '_eos_']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(0,10):\n",
    "    print([fr_itos[o] for o in x[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in y[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in preds[:,i] if o!=1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Test1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn_rev, key=lambda x: len(en_trn_rev[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val_rev, key=lambda x: len(en_val_rev[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds_2, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds_2, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 29), (25, 13), (33, 20), (33, 13), (15, 7)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_99)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2279337c0b5748668823a849bfe2e1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.782766   12.071773 \n",
      "    1      3.37465    6.194603                              \n",
      "    2      2.960599   5.946634                              \n",
      "    3      2.852992   5.763406                              \n",
      "    4      2.869113   5.0555                                \n",
      "    5      2.844296   4.4803                                \n",
      "    6      2.966632   3.896077                              \n",
      "    7      3.026155   3.786117                              \n",
      "    8      2.888877   3.748351                              \n",
      "    9      2.802807   3.583114                              \n",
      "    10     3.023529   3.545996                              \n",
      "    11     2.893101   3.529499                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.5295])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['croyez', '-', 'vous', 'que', 'le', 'secteur', 'canadien', 'du', 'porc', 'pourrait', 'mieux', 'fabler', 'sur', 'les', 'possibilités', 'du', 'marché', 'pour', 'ma~', 'son', 'potentiel', 'commercial', 'au', 'cours', 'des', 'cinq', 'prochaines', 'années', '?', '_eos_']\n",
      "['?', 'years', 'five', 'next', 'the', 'over', 'sector', 'po~', '-', 'hog', 'canadian', 'the', 'for', 'competition', 'midable', '~', 'fo', 'most', 'the', 'be', 'to', 'likely', 'are', 'feel', 'you', 'do', 'countries', 'which', '_eos_']\n",
      "['?', 'years', 'next', 'the', 'in', 'market', 'market', 'the', 'market', 'the', 'the', 'market', 'the', 'the', 'the', 'the', 'the', 'you', 'you', 'do', 'you', '_eos_', '_eos_']\n",
      "\n",
      "['quels', 'principaux', 'obstacles', 'limitent', \"l'\", 'accès', 'à', 'ces', 'marchés', 'et', 'quelles', 'mesures', \"l'\", 'industrie', 'et', 'le', 'gouvernement', 'pourraient', '-', 'ils', 'prendre', 'pour', 'rendre', 'le', 'porc', 'du', 'manitoba', 'plus', 'concurrentiel', 'sur', 'ces', 'marchés', 'en']\n",
      "['?', 'markets', 'expanding', 'these', 'in', 'competitive', 'more', 'pork', 'manitoba', 'make', 'to', 'do', 'government', 'and', 'industry', 'might', 'what', 'and', ',', 'markets', 'these', 'accessing', 'to', 'impediments', 'major', 'the', 'are', 'what', '_eos_']\n",
      "['?', 'sector', 'these', 'the', 'in', 'the', 'the', 'the', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'barriers', 'the', 'the', 'are', 'are', 'are', 'are', 'what']\n",
      "\n",
      "['quel', 'rôle', 'le', 'commissaire', 'général', 'a', '-t', '-il', 'joué', 'dans', 'la', 'promotion', 'du', 'pavillon', 'du', 'canada', 'grâce', 'à', 'sa', 'visite', 'à', 'saveur', 'technologique', 'de', 'la', 'région', 'de', 'tokyo', 'avant', \"l'\", 'expo', 'et', 'à']\n",
      "['?', 'pavilion', 'canada', 'the', 'of', 'promotion', 'the', 'in', 'play', 'coverage', 'media', 'its', 'and', 'region', 'tokyo', 'of', 'tour', 'techjin', 'expo', '-', 'pre', \"'s\", 'general', 'commissioner', 'the', 'did', 'role', 'what', '_eos_']\n",
      "['?', 'innovation', 'and', 'and', 'and', 'and', 'and', 'in', 'in', 'the', 'the', 'in', 'the', 'the', 'canada', 'canada', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'what', '_eos_', '_eos_']\n",
      "\n",
      "['quel', 'rôle', 'le', 'commissaire', 'général', 'a', '-t', '-il', 'joué', 'dans', 'la', 'promotion', 'du', 'pavillon', 'du', 'canada', 'grâce', 'à', 'sa', 'visite', 'à', 'saveur', 'technologique', 'de', 'la', 'région', 'de', 'tokyo', 'avant', 'l’', 'expo', 'et', 'à']\n",
      "['?', 'pavilion', 'canada', 'the', 'of', 'promotion', 'the', 'in', 'play', 'coverage', 'media', 'its', 'and', 'region', 'tokyo', 'of', 'tour', 'techjin', 'expo', '-', 'pre', '’s', 'general', 'commissioner', 'the', 'did', 'role', 'what', '_eos_']\n",
      "['?', 'innovation', 'and', 'and', 'and', 'and', 'and', 'in', 'in', 'the', 'the', 'in', 'the', 'canada', 'canada', 'canada', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'what', '_eos_', '_eos_']\n",
      "\n",
      "[\"qu'\", 'est', '-ce', 'que', 'les', 'expériences', 'canadiennes', 'et', 'internationales', 'nous', 'révèlent', 'des', 'effets', 'de', 'ces', 'partenariats', 'sur', \"l'\", 'accès', 'aux', 'services', ',', 'leur', 'qualité', ',', 'leurs', 'coûts', 'et', 'leurs', 'résultats', '?', '_eos_']\n",
      "['?', 'care', 'of', 'outcomes', 'and', ',', 'costs', ',', 'quality', ',', 'access', 'on', 'partnerships', 'these', 'of', 'effects', 'the', 'about', ',', 'experience', 'international', 'and', 'canadian', 'from', ',', 'known', 'is', 'what', '_eos_']\n",
      "['?', 'services', 'and', 'and', 'and', ',', ',', ',', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'what', 'what', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['quelles', 'sont', 'les', 'répercussions', 'de', 'notre', 'nouvelle', 'compréhension', 'des', 'fonctions', 'du', 'cerveau', ',', 'et', 'leurs', 'relations', 'avec', 'le', 'comportement', ',', 'la', 'personnalité', ',', 'la', 'mémoire', ',', 'et', 'les', 'autres', 'états', 'mentaux', '?', '_eos_']\n",
      "['?', 'states', 'mental', 'other', 'and', ',', 'memory', ',', 'personality', ',', 'behavior', 'to', 'relationship', 'its', 'and', ',', 'function', 'brain', 'of', 'understanding', 'developing', 'rapidly', 'our', 'of', 'implications', 'the', 'are', 'what', '_eos_']\n",
      "['?', 'states', 'and', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'the', 'the', 'the', 'the', 'the', 'what', 'what', 'what', 'what', 'what']\n",
      "\n",
      "['quel', 'devrait', 'être', 'le', 'mandat', 'stratégique', 'de', \"l'\", 'institut', 'pour', 'les', 'prochaines', 'années', ',', 'et', 'quelle', 'structure', 'serait', 'la', 'plus', 'appropriée', 'pour', \"l'\", 'accomplissement', 'de', 'ce', 'mandat', '?', '_eos_']\n",
      "['?', 'mandate', 'this', 'of', 'achievement', 'the', 'for', 'structure', 'appropriate', 'most', 'the', 'is', 'what', 'and', ',', 'years', 'coming', 'the', 'in', 'institute', 'the', 'of', 'mandate', 'strategic', 'the', 'be', 'should', 'what', '_eos_']\n",
      "['?', 'mandate', 'the', 'of', 'mandate', 'the', 'the', 'be', 'the', 'be', 'the', 'the', 'the', 'be', 'the', 'be', 'the', 'be', 'be', 'be', 'be', 'be', 'the', 'be', 'be', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['quand', 'convient', '-', 'il', 'de', 'tenir', 'compte', 'des', 'heures', 'de', 'travail', 'd’', 'une', 'personne', 'pour', 'déterminer', 'si', 'une', 'installation', 'atteint', 'ou', 'dépasse', 'le', 'seuil', 'des', '20', '000', 'heures', 'de', 'travail', 'établi', '?', '_eos_']\n",
      "['?', 'exceeded', 'is', 'threshold', 'hour', '000', '20', 'the', 'not', 'or', 'whether', 'determining', 'of', 'purposes', 'for', 'counted', 'be', 'facility', 'a', 'at', 'working', 'spent', 'time', '’s', 'individual', 'an', 'should', 'when', '_eos_']\n",
      "['?', 'hours', 'hours', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'to', 'to', 'to', 'to', 'to', '_eos_', '_eos_', '_eos_', '_eos_', '_eos_']\n",
      "\n",
      "['pourquoi', 'l’', 'organisme', 'a', '-t', '-il', 'sollicité', 'l’', 'apport', 'du', 'public', 'et', 'qu’', 'est', '-ce', 'qui', 'a', 'bien', 'pu', 'susciter', 'cette', 'forte', 'réponse', ',', 'alors', 'que', 'd’', 'autres', 'appels', 'de', 'la', 't_up', 'fec']\n",
      "['comments', 'so', 'or', 'dozen', 'a', 'only', 'generate', 'might', 'requests', 'fec', 't_up', 'other', 'while', ',', 'response', 'large', 'the', 'prompted', 'what', 'and', 'input', 'public', 'for', 'ask', 'agency', 'the', 'did', 'why', '?']\n",
      "['?', 'that', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'why', 'why', 'why', 'why', 'why', 'why', '_eos_']\n",
      "\n",
      "['quelles', 'mesures', 'faudrait', '-', 'il', 'envisager', 'en', 'vue', 'de', 'réduire', 'le', 'risque', 'si', 'les', 'tests', 'de', 'dépistage', 'du', 't_up', 'vwn', 'ne', 'sont', 'pas', 'disponibles', '?', '_eos_']\n",
      "['attention', 'focused', 'need', 'research', 'wnv', 't_up', 'of', 'areas', 'what', ',', 'finally', 'and', 'available', 'not', 'are', 'wnv', 't_up', 'for', 'tests', 'if', 'risk', 'reduce', 'to', 'considered', 'be', 'should', 'measures', 'what', '?']\n",
      "['?', 'available', 'be', 'not', 'testing', 't_up', 't_up', 'if', 'risk', 'the', 'the', 'should', 'should', 'what', 'what', 'what']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(0,10):\n",
    "    #print (len(x[:,i]))\n",
    "    print([fr_itos[o] for o in x[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in y[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in preds[:,i] if o!=1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn_rev, key=lambda x: len(en_trn_rev[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val_rev, key=lambda x: len(en_val_rev[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds_3, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds_3, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 29), (33, 15), (33, 24), (21, 8), (29, 16)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_99)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746464b388c549b6a08100d5955e52ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      3.846422   15.127836 \n",
      "    1      3.09523    7.713141                              \n",
      "    2      2.815066   7.12444                               \n",
      "    3      2.821907   6.299391                              \n",
      "    4      2.755504   4.710751                              \n",
      "    5      2.888454   4.240161                              \n",
      "    6      2.877773   4.031064                              \n",
      "    7      2.881096   3.861464                              \n",
      "    8      2.856704   3.692176                              \n",
      "    9      2.96854    3.587662                              \n",
      "    10     3.002486   3.553226                              \n",
      "    11     2.920857   3.495219                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.49522])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('Test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('Test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'années', 'prochaines', 'cinq', 'des', 'cours', 'au', 'commercial', 'potentiel', 'son', 'ma~', 'pour', 'marché', 'du', 'possibilités', 'les', 'sur', 'fabler', 'mieux', 'pourrait', 'porc', 'du', 'canadien', 'secteur', 'le', 'que', 'vous', '-', 'croyez', '_eos_']\n",
      "['?', 'years', 'five', 'next', 'the', 'over', 'sector', 'po~', '-', 'hog', 'canadian', 'the', 'for', 'competition', 'midable', '~', 'fo', 'most', 'the', 'be', 'to', 'likely', 'are', 'feel', 'you', 'do', 'countries', 'which', '_eos_']\n",
      "['?', 'years', 'next', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'you', 'you', 'you', 'you', 'you', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['marchés', 'ces', 'sur', 'concurrentiel', 'plus', 'manitoba', 'du', 'porc', 'le', 'rendre', 'pour', 'prendre', 'ils', '-', 'pourraient', 'gouvernement', 'le', 'et', 'industrie', \"l'\", 'mesures', 'quelles', 'et', 'marchés', 'ces', 'à', 'accès', \"l'\", 'limitent', 'obstacles', 'principaux', 'quels', 'en']\n",
      "['?', 'markets', 'expanding', 'these', 'in', 'competitive', 'more', 'pork', 'manitoba', 'make', 'to', 'do', 'government', 'and', 'industry', 'might', 'what', 'and', ',', 'markets', 'these', 'accessing', 'to', 'impediments', 'major', 'the', 'are', 'what', '_eos_']\n",
      "['?', 'markets', 'market', 'the', 'markets', 'markets', 'the', 'and', 'and', 'and', 'to', 'to', 'to', 'to', 'to', 'the', 'the', 'the', 'the', 'the', 'what', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['et', 'expo', \"l'\", 'avant', 'tokyo', 'de', 'région', 'la', 'de', 'technologique', 'saveur', 'à', 'visite', 'sa', 'à', 'grâce', 'canada', 'du', 'pavillon', 'du', 'promotion', 'la', 'dans', 'joué', '-il', '-t', 'a', 'général', 'commissaire', 'le', 'rôle', 'quel', 'à']\n",
      "['?', 'pavilion', 'canada', 'the', 'of', 'promotion', 'the', 'in', 'play', 'coverage', 'media', 'its', 'and', 'region', 'tokyo', 'of', 'tour', 'techjin', 'expo', '-', 'pre', \"'s\", 'general', 'commissioner', 'the', 'did', 'role', 'what', '_eos_']\n",
      "['?', 'expo', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'in', 'play', 'and', 'and', 'the', 'the', 'role', 'role', 'role', 'the', 'role', 'the', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['et', 'expo', 'l’', 'avant', 'tokyo', 'de', 'région', 'la', 'de', 'technologique', 'saveur', 'à', 'visite', 'sa', 'à', 'grâce', 'canada', 'du', 'pavillon', 'du', 'promotion', 'la', 'dans', 'joué', '-il', '-t', 'a', 'général', 'commissaire', 'le', 'rôle', 'quel', 'à']\n",
      "['?', 'pavilion', 'canada', 'the', 'of', 'promotion', 'the', 'in', 'play', 'coverage', 'media', 'its', 'and', 'region', 'tokyo', 'of', 'tour', 'techjin', 'expo', '-', 'pre', '’s', 'general', 'commissioner', 'the', 'did', 'role', 'what', '_eos_']\n",
      "['?', 'expo', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'and', 'in', 'in', 'play', 'and', 'and', 'the', 'the', 'role', 'role', 'role', 'the', 'role', 'the', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['?', 'résultats', 'leurs', 'et', 'coûts', 'leurs', ',', 'qualité', 'leur', ',', 'services', 'aux', 'accès', \"l'\", 'sur', 'partenariats', 'ces', 'de', 'effets', 'des', 'révèlent', 'nous', 'internationales', 'et', 'canadiennes', 'expériences', 'les', 'que', '-ce', 'est', \"qu'\", '_eos_']\n",
      "['?', 'care', 'of', 'outcomes', 'and', ',', 'costs', ',', 'quality', ',', 'access', 'on', 'partnerships', 'these', 'of', 'effects', 'the', 'about', ',', 'experience', 'international', 'and', 'canadian', 'from', ',', 'known', 'is', 'what', '_eos_']\n",
      "['?', 'providers', 'their', 'and', 'and', 'and', ',', ',', ',', ',', ',', ',', 'and', 'and', ',', 'and', 'and', 'about', 'what', 'what', 'what', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['?', 'mentaux', 'états', 'autres', 'les', 'et', ',', 'mémoire', 'la', ',', 'personnalité', 'la', ',', 'comportement', 'le', 'avec', 'relations', 'leurs', 'et', ',', 'cerveau', 'du', 'fonctions', 'des', 'compréhension', 'nouvelle', 'notre', 'de', 'répercussions', 'les', 'sont', 'quelles', '_eos_']\n",
      "['?', 'states', 'mental', 'other', 'and', ',', 'memory', ',', 'personality', ',', 'behavior', 'to', 'relationship', 'its', 'and', ',', 'function', 'brain', 'of', 'understanding', 'developing', 'rapidly', 'our', 'of', 'implications', 'the', 'are', 'what', '_eos_']\n",
      "['?', 'states', 'and', 'and', ',', ',', ',', ',', ',', ',', ',', ',', ',', 'and', 'and', 'and', 'understanding', 'of', 'understanding', 'our', 'of', 'understanding', 'the', 'the', 'what', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['?', 'mandat', 'ce', 'de', 'accomplissement', \"l'\", 'pour', 'appropriée', 'plus', 'la', 'serait', 'structure', 'quelle', 'et', ',', 'années', 'prochaines', 'les', 'pour', 'institut', \"l'\", 'de', 'stratégique', 'mandat', 'le', 'être', 'devrait', 'quel', '_eos_']\n",
      "['?', 'mandate', 'this', 'of', 'achievement', 'the', 'for', 'structure', 'appropriate', 'most', 'the', 'is', 'what', 'and', ',', 'years', 'coming', 'the', 'in', 'institute', 'the', 'of', 'mandate', 'strategic', 'the', 'be', 'should', 'what', '_eos_']\n",
      "['?', 'mandate', 'this', 'for', 'for', 'be', 'to', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'what', 'what', 'what', '_eos_']\n",
      "\n",
      "['?', 'établi', 'travail', 'de', 'heures', '000', '20', 'des', 'seuil', 'le', 'dépasse', 'ou', 'atteint', 'installation', 'une', 'si', 'déterminer', 'pour', 'personne', 'une', 'd’', 'travail', 'de', 'heures', 'des', 'compte', 'tenir', 'de', 'il', '-', 'convient', 'quand', '_eos_']\n",
      "['?', 'exceeded', 'is', 'threshold', 'hour', '000', '20', 'the', 'not', 'or', 'whether', 'determining', 'of', 'purposes', 'for', 'counted', 'be', 'facility', 'a', 'at', 'working', 'spent', 'time', '’s', 'individual', 'an', 'should', 'when', '_eos_']\n",
      "['?', 'hours', 'working', 'of', 'of', 'the', 'of', 'the', 'the', 'the', 'the', 'the', 'the', 'a', 'a', 'a', 'a', 'when', 'when', '_eos_', '_eos_', '_eos_']\n",
      "\n",
      "['t_up', 'la', 'de', 'appels', 'autres', 'd’', 'que', 'alors', ',', 'réponse', 'forte', 'cette', 'susciter', 'pu', 'bien', 'a', 'qui', '-ce', 'est', 'qu’', 'et', 'public', 'du', 'apport', 'l’', 'sollicité', '-il', '-t', 'a', 'organisme', 'l’', 'pourquoi', 'fec']\n",
      "['comments', 'so', 'or', 'dozen', 'a', 'only', 'generate', 'might', 'requests', 'fec', 't_up', 'other', 'while', ',', 'response', 'large', 'the', 'prompted', 'what', 'and', 'input', 'public', 'for', 'ask', 'agency', 'the', 'did', 'why', '?']\n",
      "['?', 'other', 'other', ',', ',', ',', ',', ',', ',', ',', ',', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'why', 'why', 'why', 'why', '_eos_']\n",
      "\n",
      "['?', 'disponibles', 'pas', 'sont', 'ne', 'vwn', 't_up', 'du', 'dépistage', 'de', 'tests', 'les', 'si', 'risque', 'le', 'réduire', 'de', 'vue', 'en', 'envisager', 'il', '-', 'faudrait', 'mesures', 'quelles', '_eos_']\n",
      "['attention', 'focused', 'need', 'research', 'wnv', 't_up', 'of', 'areas', 'what', ',', 'finally', 'and', 'available', 'not', 'are', 'wnv', 't_up', 'for', 'tests', 'if', 'risk', 'reduce', 'to', 'considered', 'be', 'should', 'measures', 'what', '?']\n",
      "['?', 'available', 'not', 'testing', 'testing', 'testing', 'testing', 'of', 'of', 'the', 'the', 'the', 'be', 'what', 'what', 'what', '_eos_']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    print([fr_itos[o] for o in x[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in y[:,i] if o != 1])\n",
    "    print([en_itos[o] for o in preds[:,i] if o!=1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing_LSTM(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.lstm_enc = nn.LSTM(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.lstm_dec = nn.LSTM(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
